{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
       "dataset_name = \"cifar10\"\n",
       "model_type = \"cnn\" \n",
       "nump_epochs = 40\n",
       "pth = \"./trajectories\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "!pip install ipywidgets"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
       "scrolled": false
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "True\n"
        ]
       }
      ],
      "source": [
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.optim as optim\n",
       "from torchvision import datasets, transforms\n",
       "from torch.utils.data import DataLoader\n",
       "import torch.nn.functional as F\n",
       "\n",
       "\n",
       "\n",
       "img_size =  4\n",
       "ch_size = 3\n",
       "# Define the ConvNet architecture\n",
       "class ConvNet(nn.Module):\n",
       "    def __init__(self):\n",
       "        super(ConvNet, self).__init__()\n",
       "        self.conv1 = nn.Conv2d(ch_size, 8, kernel_size=3, padding=1)  # 1 input channel, 8 output channels\n",
       "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1) # 8 input channels, 16 output channels\n",
       "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # 8 input channels, 16 output channels\n",
       "        self.fc1 = nn.Linear(32 * img_size * img_size, 120)   # Fully connected layer with 120 neurons\n",
       "        self.fc2 = nn.Linear(120, 10)           # Output layer with 10 neurons (10 classes)\n",
       "\n",
       "    def forward(self, x):\n",
       "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
       "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
       "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
       "        x = x.view(-1, 32 * img_size * img_size)\n",
       "        x = F.relu(self.fc1(x))\n",
       "        x = self.fc2(x)\n",
       "        return F.log_softmax(x, dim=1)\n",
       "\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
       "class EarlyStopping:\n",
       "    def __init__(self, patience=5, min_delta=0):\n",
       "        self.patience = patience\n",
       "        self.min_delta = min_delta\n",
       "        self.counter = 0\n",
       "        self.best_loss = None\n",
       "        self.early_stop = False\n",
       "\n",
       "    def __call__(self, val_loss):\n",
       "        if self.best_loss is None:\n",
       "            self.best_loss = val_loss\n",
       "        elif val_loss > self.best_loss - self.min_delta:\n",
       "            self.counter += 1\n",
       "            if self.counter >= self.patience:\n",
       "                self.early_stop = True\n",
       "        else:\n",
       "            self.best_loss = val_loss\n",
       "            self.counter = 0\n",
       "\n",
       "# Instantiate early stopping\n",
       "early_stopping = EarlyStopping(patience=3, min_delta=0.01)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Files already downloaded and verified\n"
        ]
       }
      ],
      "source": [
       "if dataset_name == \"mnist\":\n",
       "    transform = transforms.Compose([\n",
       "        transforms.ToTensor(),\n",
       "        transforms.Normalize((0.1307,), (0.3081,))\n",
       "    ])\n",
       "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
       "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
       "else:\n",
       "    transform = transforms.Compose([\n",
       "        transforms.RandomHorizontalFlip(),\n",
       "        transforms.RandomRotation(10),\n",
       "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
       "        transforms.ToTensor(),\n",
       "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
       "    ])\n",
       "    transform2 = transforms.Compose([\n",
       "        transforms.ToTensor(),\n",
       "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
       "    ])\n",
       "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)                              \n",
       "    test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform2)\n",
       "\n",
       "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
       "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
       "\n",
       "\n",
       "# Define the training loop\n",
       "def train(epoch, model, optimizer):\n",
       "    model.train()\n",
       "    for batch_idx, (data, target) in enumerate(train_loader):\n",
       "        optimizer.zero_grad()\n",
       "        output = model(data.cuda())\n",
       "        loss = F.nll_loss(output, target.cuda())\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "        if batch_idx % 100 == 0:\n",
       "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
       "\n",
       "# Define the test loop\n",
       "def test(epoch, model, optimizer):\n",
       "    model.eval()\n",
       "    test_loss = 0\n",
       "    correct = 0\n",
       "    with torch.no_grad():\n",
       "        for data, target in test_loader:\n",
       "            output = model(data.cuda())\n",
       "            test_loss += F.nll_loss(output, target.cuda(), reduction='sum').item()  # Sum up batch loss\n",
       "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
       "            correct += pred.eq(target.cuda().view_as(pred)).sum().item()\n",
       "    test_loss /= len(test_loader.dataset)\n",
       "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
       "    return test_loss\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "\n",
       "# Initialize the model and optimizer\n",
       "model = ConvNet()\n",
       "model=model.cuda()\n",
       "optimizer = optim.SGD(model.parameters(), lr= 0.001, momentum=0.9, weight_decay=1e-4)\n",
       "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  'min',factor=0.5, patience=2)\n",
       "\n",
       "\n",
       "    \n",
       "    \n",
       "def save_model(epoch, model):\n",
       "    # Save the model after each epoch\n",
       "    save_path = f'{pth}/models_{model_type}_{dataset_name}/model_epoch_{epoch}.pt'\n",
       "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
       "    torch.save(model.state_dict(), save_path)\n",
       "    print(f'Model saved to {save_path}')\n",
       "    \n",
       "# Train and test the model with early stopping\n",
       "save_model(0, model)\n",
       "for epoch in range(1, nump_epochs + 1):\n",
       "    train(epoch, model, optimizer)\n",
       "    val_loss = test(epoch, model, optimizer)\n",
       "    scheduler.step(val_loss)\n",
       "    early_stopping(val_loss)    \n",
       "    save_model(epoch, model)\n",
       "    if early_stopping.early_stop:\n",
       "        print(\"Early stopping triggered\")\n",
       "        break\n",
       "    \n",
       "\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from torchsummary import summary\n",
       "\n",
       "img_dim  =4 *8\n",
       "summary(model, input_size=(3, img_dim, img_dim))  # Input size should match the input dimensions of your model\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "landscapesvisenv",
      "language": "python",
      "name": "landscapesvisenv"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   